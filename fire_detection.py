# -*- coding: utf-8 -*-
"""fire_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VD8SUYVoozFZ_6SdpxLTHB2nhVXZMVu7

# Import modules
"""

import numpy as np
import matplotlib.pyplot as plt

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import load_model, Model

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.metrics import ConfusionMatrixDisplay

import os

seed = 42
np.random.seed(seed)
tf.random.set_seed(seed)

"""#Mount Google Drive"""

from google.colab import drive
drive.mount('/content/drive')

"""# Training and testing data paths"""

training_data_path = '/content/drive/MyDrive/Colab Notebooks/Forest_Fire_Dataset/Forest_Fire_Dataset/Training'
testing_data_path = '/content/drive/MyDrive/Colab Notebooks/Forest_Fire_Dataset/Forest_Fire_Dataset/Testing'

"""# Data preprocessing"""

from tensorflow.keras.preprocessing.image import ImageDataGenerator

train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)
test_datagen = ImageDataGenerator(rescale=1./255)

train_generator = train_datagen.flow_from_directory(
    training_data_path,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    shuffle=True,
    seed=42,
    subset='training'
)

val_generator = train_datagen.flow_from_directory(
    training_data_path,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    shuffle=False,
    seed=42,
    subset='validation'
)

test_generator = test_datagen.flow_from_directory(
    testing_data_path,
    target_size=(150, 150),
    batch_size=32,
    class_mode='binary',
    shuffle=False,
    seed=42
)

print(f"Number of training images: {train_generator.samples}")
print(f"Number of validation images: {val_generator.samples}")
print(f"Number of testing images: {test_generator.samples}")

"""# CNN-Sigmoid model architecture"""

model = Sequential([
    Input(shape=(150, 150, 3)),
    Conv2D(32, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Dropout(0.2),
    Conv2D(64, (3,3), activation='relu'),
    MaxPooling2D(2,2),
    Flatten(),
    Dense(128, activation='relu'),
    Dense(1, activation='sigmoid')
])

optimizer = Adam(learning_rate=0.001)

model.compile(optimizer=optimizer,
              loss='binary_crossentropy',
              metrics=['accuracy'])

model.summary()

"""#Train CNN-Sigmoid model"""

history = model.fit(
    train_generator,
    epochs=20,
    validation_data=val_generator,
    verbose=1
)

"""# Save trained model

"""

model.save('cnn_sigmoid_model.keras')

"""# Plot Training vs Validation Accuracy"""

plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training vs Validation Accuracy')
plt.show()

"""# Plot Training vs Validation Loss"""

plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.title('Training vs Validation Loss')
plt.show()

"""# Evaluate model"""

loss, accuracy = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")

y_true = test_generator.classes
y_pred_probs = model.predict(test_generator, steps=test_generator.samples // test_generator.batch_size + 1)
y_pred = (y_pred_probs > 0.5).astype(int).flatten()

# Print Classification Report
print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=test_generator.class_indices.keys()))

"""# Plot Confusion matrix"""

cm = confusion_matrix(y_true, y_pred)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=test_generator.class_indices.keys())
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix')
plt.show()

"""# Load CNN-Sigmoid model"""

model = load_model('/content/cnn_sigmoid_model.h5')  # Make sure path is correct

# Dummy input to initialize model (optional)
dummy_input = np.zeros((1, 150, 150, 3))
_ = model(dummy_input)

# Create CNN feature extractor (remove last Dense layer)
input_tensor = Input(shape=(150, 150, 3))
x = input_tensor
for layer in model.layers[:-1]:  # Exclude final Dense(1, sigmoid) layer
    x = layer(x)

cnn_feature_extractor = Model(inputs=input_tensor, outputs=x)
cnn_feature_extractor.trainable = False

"""# Train CNN-SVM model"""

from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import make_pipeline

# Create a pipeline: StandardScaler + Linear SVM
svm_model = make_pipeline(StandardScaler(), SVC(kernel='linear', probability=True))

# Extract features and labels from training set
all_features = []
all_labels = []

for i in range(len(train_generator)):
    imgs, lbls = train_generator[i]
    feats = cnn_feature_extractor.predict(imgs)
    feats = feats.reshape(feats.shape[0], -1)  # Flatten CNN features
    all_features.append(feats)
    all_labels.append(lbls)

# Stack batches into single arrays
X_train = np.vstack(all_features)
y_train = np.hstack(all_labels)

# Train SVM
svm_model.fit(X_train, y_train)

"""#Extract test features and run predictions"""

# Extract features and labels from test set
test_features = []
test_labels = []

for i in range(len(test_generator)):
    imgs, lbls = test_generator[i]
    feats = cnn_feature_extractor.predict(imgs)
    feats = feats.reshape(feats.shape[0], -1)
    test_features.append(feats)
    test_labels.append(lbls)

# Stack batches into single arrays
X_test = np.vstack(test_features)
y_test = np.hstack(test_labels)

# Predict test labels
y_pred_svm = svm_model.predict(X_test)

"""# Evaluate CNN-SVM model"""

from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# Test Accuracy
test_accuracy_svm = accuracy_score(y_test, y_pred_svm)
print(f"Test Accuracy (CNN-SVM): {test_accuracy_svm:.4f}")

# Classification Report
print("\nClassification Report (CNN-SVM):")
print(classification_report(y_test, y_pred_svm, target_names=test_generator.class_indices.keys()))

# Confusion Matrix
cm_svm = confusion_matrix(y_test, y_pred_svm)
print("\nConfusion Matrix (CNN-SVM):")
print(cm_svm)

# Plot Confusion Matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm_svm, display_labels=test_generator.class_indices.keys())
disp.plot(cmap=plt.cm.Blues)
plt.title('Confusion Matrix (CNN-SVM)')
plt.show()